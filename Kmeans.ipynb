{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ####################################################################\n",
    "#\n",
    "#  LIBRARY\n",
    "#    normalizer\n",
    "#\n",
    "#  DESCRIPTION\n",
    "#    The aim of this library is to have normalizer helper functions to\n",
    "#  apply to the datasets. So since it's often to have to normalize and\n",
    "#  translate data from one value to another, we have created a library\n",
    "#  here that does that for us in a simple manner.\n",
    "#\n",
    "#    The library assumes that the input is a dataframe (df) which is\n",
    "#  the objects generated by the Pandas library.\n",
    "#\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "#  normalize_string\n",
    "#    df : [Pandas dataFrame]\n",
    "#    column : [String] name of the column you want to normalize\n",
    "#    mapping : [Python associatve array]\n",
    "#\n",
    "#  This function converts all the columns on a given dataframe from\n",
    "#  a string to some value specified in a mapping.\n",
    "#  The big difference between the previous version of this, is that\n",
    "#  the user MUST know what is the mapping beforehand.\n",
    "#  This is particularly useful when you WANT to know how the string\n",
    "#  values were replaced by numbers.\n",
    "# --------------------------------------------------------------------\n",
    "def normalize_string_mapping(df, column, mapping):\n",
    "    df[column].replace(mapping, inplace=True)\n",
    "\n",
    "\n",
    "#  normalize_amount\n",
    "#    df : [Pandas dataFrame]\n",
    "#    column : [String] name of the column you want to normalize\n",
    "#    round_to : [integer number]\n",
    "#\n",
    "#  This function remove \"in between\" numbers in a \"floor\" manner.\n",
    "#  So for example if you have the numbers [5, 10, 12, 20, 24] and you\n",
    "#  round to 10, then your set will end up being [5, 10, 10, 20, 20]\n",
    "#  because all the numbers inbetween will be \"floored\" to the lower\n",
    "#  number that is divided by 10.\n",
    "# --------------------------------------------------------------------\n",
    "def normalize_amount(df, column, round_to=2500):\n",
    "    df[column] = df[column].apply(lambda x: int(x)-(int(x) % round_to))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "from lib.cartasur.constants import *\n",
    "from lib.cartasur.normalizer import normalize_amount\n",
    "from lib.cartasur.normalizer import normalize_string_mapping\n",
    "\n",
    "#  This function serves as a dataset loader.py\n",
    "# --------------------------------------------------------------------\n",
    "def load_dataset(filename):\n",
    "    print(\"[i] Loading file {}\".format(filename))\n",
    "    separator = \";\"\n",
    "    encoding = \"ISO8859-1\"\n",
    "    return pd.read_csv(filename, sep=separator, encoding=encoding)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Loading Datasets\n",
      "[i] Loading file C:\\Users\\Guillo\\2020\\UP\\PROYECTOS\\UP_ML_cartasur\\data\\PAGOS.csv\n",
      "[i] Loading file C:\\Users\\Guillo\\2020\\UP\\PROYECTOS\\UP_ML_cartasur\\data\\CUOTAS.csv\n",
      "[i] Loading file C:\\Users\\Guillo\\2020\\UP\\PROYECTOS\\UP_ML_cartasur\\data\\CLIENTES.csv\n",
      "[i] Loading file C:\\Users\\Guillo\\2020\\UP\\PROYECTOS\\UP_ML_cartasur\\data\\CREDITOS.csv\n",
      "Finished in 5.09 secs\n"
     ]
    }
   ],
   "source": [
    "#  This function loads\n",
    "# --------------------------------------------------------------------\n",
    "#def load_merge_all_datasets(dataset_directory, drop_columns=None):\n",
    "dataset_directory= \"C:\\\\Users\\\\Guillo\\\\2020\\\\UP\\\\PROYECTOS\\\\UP_ML_cartasur\\\\data\\\\\"\n",
    "print(\"[i] Loading Datasets\")\n",
    "start = time.time()\n",
    "pagos = load_dataset(\"{}PAGOS.csv\".format(dataset_directory))\n",
    "cuotas = load_dataset(\"{}CUOTAS.csv\".format(dataset_directory))\n",
    "clientes = load_dataset(\"{}CLIENTES.csv\".format(dataset_directory))\n",
    "creditos = load_dataset(\"{}CREDITOS.csv\".format(dataset_directory))\n",
    "end = time.time()\n",
    "print(\"Finished in {} secs\".format(round(end-start,2)))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------------------------------------------------------\n",
    "#\n",
    "#  LIBRARY\n",
    "#    cartasur.constants\n",
    "#\n",
    "#  DESCRIPTION\n",
    "#    This file include all the contants / mappings we need to\n",
    "#    normalize the information on the files\n",
    "#\n",
    "#---------------------------------------------------------------------\n",
    "CLASE_PLAN = {\n",
    "    'RENOVADOR'  :  1,\n",
    "    'NUEVO'      :  2\n",
    "}\n",
    "\n",
    "\n",
    "METALES = {\n",
    "    'ALUMINIO'  :  1,\n",
    "    'BRONCE'    :  2,\n",
    "    'BRONCE_B'  :  3,\n",
    "    'NUEVO'     :  4,\n",
    "    'NUEVO_B'   :  5,\n",
    "    'ORO'       :  6,\n",
    "    'ORO_B'     :  7,\n",
    "    'PLATA'     :  8,\n",
    "    'PLATA_B'   :  9,\n",
    "    'PLATINO'   : 10,\n",
    "    'PLATINO_B' : 11,\n",
    "    'POSREFI'   : 12,\n",
    "    'POSREFIB'  : 13\n",
    "}\n",
    "\n",
    "\n",
    "TIPO_LABORAL = {\n",
    "    'Cooperativista'      : 1,\n",
    "    'Empleada Domestica'  : 2,\n",
    "    'JUBILADO'            : 3,\n",
    "    'MONOTRIBUTISTA'      : 4,\n",
    "    'NODEFINIDA'          : 5,\n",
    "    'PUBLICA'             : 6,\n",
    "    'Pension Graciable'   : 7,\n",
    "    'Plan Social'         : 8,\n",
    "    'Privada'             : 9,\n",
    "    'SIN RECIBO'          : 10\n",
    "}\n",
    "\n",
    "\n",
    "SEXO = {\n",
    "    'D' : 0,\n",
    "    'F' : 1,\n",
    "    'M' : 2\n",
    "}\n",
    "\n",
    "\n",
    "SUCURSAL_Y = {\n",
    "    'Alejandro Korn'   : 1,\n",
    "    'Avellaneda'       : 2,\n",
    "    'Brandsen'         : 3,\n",
    "    'Burzaco'          : 4,\n",
    "    'CallCenter'       : 5,\n",
    "    'Casa Central'     : 6,\n",
    "    'Caseros'          : 7,\n",
    "    'Cañuelas'         : 8,\n",
    "    'Chascomús'        : 9,\n",
    "    'Ezeiza'           : 10,\n",
    "    'Florencio Varela' : 11,\n",
    "    'Flores'           : 12,\n",
    "    'Glew'             : 13,\n",
    "    'La Plata'         : 14,\n",
    "    'Laferrere'        : 15,\n",
    "    'Lanús'            : 16,\n",
    "    'Liniers'          : 17,\n",
    "    'Lomas'            : 18,\n",
    "    'Los Polvorines'   : 19,\n",
    "    'Monte Grande'     : 20,\n",
    "    'Moreno'           : 21,\n",
    "    'Morón'            : 22,\n",
    "    'Once'             : 23,\n",
    "    'Pompeya'          : 24,\n",
    "    'Merlo'            : 25,\n",
    "    'Quilmes'          : 26,\n",
    "    'Rafael Castillo'  : 27,\n",
    "    'San José'         : 28,\n",
    "    'San Justo'        : 29,\n",
    "    'San Miguel'       : 30,\n",
    "    'Solano'           : 31,\n",
    "    'Sucursal Web'     : 32\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID_CLIENTE  TDOC  NROC SEXO                    FALTA  \\\n",
      "0         1662448   NaN   NaN    M  1900-01-01 00:00:00.000   \n",
      "1         1662458   NaN   NaN    M  1900-01-01 00:00:00.000   \n",
      "2         1662470   NaN   NaN    M  1900-01-01 00:00:00.000   \n",
      "3         1662560   NaN   NaN    F  1900-01-01 00:00:00.000   \n",
      "4         1662583   NaN   NaN    M  1900-01-01 00:00:00.000   \n",
      "...           ...   ...   ...  ...                      ...   \n",
      "64524     2472853   NaN   NaN    F  2019-12-30 00:00:00.000   \n",
      "64525     2472858   NaN   NaN    M  2019-12-30 00:00:00.000   \n",
      "64526     2472862   NaN   NaN    F  2019-12-30 00:00:00.000   \n",
      "64527     2472869   NaN   NaN    F  2019-12-30 00:00:00.000   \n",
      "64528     2472878   NaN   NaN    F  2019-12-30 00:00:00.000   \n",
      "\n",
      "                          FNAC  INGRESO_NETO  FECHA_ALTA_LABORAL  SUCURSAL  \\\n",
      "0      1947-09-09 00:00:00.000       27000.0                 NaN       NaN   \n",
      "1      1945-12-10 00:00:00.000       16000.0                 NaN       NaN   \n",
      "2      1961-10-18 00:00:00.000       48105.0                 NaN       NaN   \n",
      "3      1973-01-12 00:00:00.000       18183.0                 NaN       NaN   \n",
      "4      1953-03-19 00:00:00.000       52337.0                 NaN       NaN   \n",
      "...                        ...           ...                 ...       ...   \n",
      "64524  1988-10-18 00:00:00.000       15000.0                 NaN       NaN   \n",
      "64525  1974-01-09 00:00:00.000       24941.0                 NaN       NaN   \n",
      "64526  1964-04-16 00:00:00.000           0.0                 NaN       NaN   \n",
      "64527  1999-06-04 00:00:00.000        8500.0                 NaN       NaN   \n",
      "64528  1996-02-14 00:00:00.000       16397.0                 NaN       NaN   \n",
      "\n",
      "         PROVINCIA_PER COD_POSTAL_PER TIPOLABORAL      METAL  \n",
      "0         BUENOS AIRES           1804    JUBILADO  PLATINO_B  \n",
      "1         BUENOS AIRES           1804    JUBILADO   POSREFIB  \n",
      "2         BUENOS AIRES           1804     PUBLICA   POSREFIB  \n",
      "3         BUENOS AIRES           1846     Privada    PLATINO  \n",
      "4         BUENOS AIRES           1804    JUBILADO        ORO  \n",
      "...                ...            ...         ...        ...  \n",
      "64524  CAPITAL FEDERAL           1436  SIN RECIBO        ORO  \n",
      "64525     BUENOS AIRES           1870     Privada      NUEVO  \n",
      "64526     BUENOS AIRES           1752  SIN RECIBO      NUEVO  \n",
      "64527     BUENOS AIRES           1778  SIN RECIBO    NUEVO_B  \n",
      "64528     BUENOS AIRES           1665     Privada    NUEVO_B  \n",
      "\n",
      "[64529 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(clientes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp1 = clientes.merge(creditos, left_on=\"ID_CLIENTE\", right_on=\"ID_CLIENTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = temp1.merge(pagos, left_on=\"ID_CREDITO\", right_on=\"ID_CREDITO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID_CLIENTE  TDOC_x  NROC SEXO                    FALTA  \\\n",
      "0          1662448     NaN   NaN    M  1900-01-01 00:00:00.000   \n",
      "1          1662448     NaN   NaN    M  1900-01-01 00:00:00.000   \n",
      "2          1662458     NaN   NaN    M  1900-01-01 00:00:00.000   \n",
      "3          1662470     NaN   NaN    M  1900-01-01 00:00:00.000   \n",
      "4          1662470     NaN   NaN    M  1900-01-01 00:00:00.000   \n",
      "...            ...     ...   ...  ...                      ...   \n",
      "119141     2472853     NaN   NaN    F  2019-12-30 00:00:00.000   \n",
      "119142     2472858     NaN   NaN    M  2019-12-30 00:00:00.000   \n",
      "119143     2472862     NaN   NaN    F  2019-12-30 00:00:00.000   \n",
      "119144     2472869     NaN   NaN    F  2019-12-30 00:00:00.000   \n",
      "119145     2472878     NaN   NaN    F  2019-12-30 00:00:00.000   \n",
      "\n",
      "                           FNAC  INGRESO_NETO  FECHA_ALTA_LABORAL  SUCURSAL_x  \\\n",
      "0       1947-09-09 00:00:00.000       27000.0                 NaN         NaN   \n",
      "1       1947-09-09 00:00:00.000       27000.0                 NaN         NaN   \n",
      "2       1945-12-10 00:00:00.000       16000.0                 NaN         NaN   \n",
      "3       1961-10-18 00:00:00.000       48105.0                 NaN         NaN   \n",
      "4       1961-10-18 00:00:00.000       48105.0                 NaN         NaN   \n",
      "...                         ...           ...                 ...         ...   \n",
      "119141  1988-10-18 00:00:00.000       15000.0                 NaN         NaN   \n",
      "119142  1974-01-09 00:00:00.000       24941.0                 NaN         NaN   \n",
      "119143  1964-04-16 00:00:00.000           0.0                 NaN         NaN   \n",
      "119144  1999-06-04 00:00:00.000        8500.0                 NaN         NaN   \n",
      "119145  1996-02-14 00:00:00.000       16397.0                 NaN         NaN   \n",
      "\n",
      "          PROVINCIA_PER  ... NDOC FECHAINFORME             FLIQUIDACION  \\\n",
      "0          BUENOS AIRES  ...  NaN   27/07/2020  2019-12-24 10:01:10.000   \n",
      "1          BUENOS AIRES  ...  NaN   27/07/2020  2019-09-12 15:43:40.000   \n",
      "2          BUENOS AIRES  ...  NaN   27/07/2020  2019-05-13 15:51:48.000   \n",
      "3          BUENOS AIRES  ...  NaN   27/07/2020  2019-10-10 16:06:48.000   \n",
      "4          BUENOS AIRES  ...  NaN   27/07/2020  2019-01-23 10:17:35.000   \n",
      "...                 ...  ...  ...          ...                      ...   \n",
      "119141  CAPITAL FEDERAL  ...  NaN   27/07/2020  2019-12-30 17:58:45.000   \n",
      "119142     BUENOS AIRES  ...  NaN   27/07/2020  2019-12-30 17:47:56.000   \n",
      "119143     BUENOS AIRES  ...  NaN   27/07/2020  2019-12-30 18:32:51.000   \n",
      "119144     BUENOS AIRES  ...  NaN   27/07/2020  2019-12-30 18:28:43.000   \n",
      "119145     BUENOS AIRES  ...  NaN   27/07/2020  2019-12-30 18:21:11.000   \n",
      "\n",
      "        CODIGO  ID_CREDITO     MONTO  SUCURSAL_y              NOMBRE  RECIBO  \\\n",
      "0            7     5467740  31180.16      Ezeiza    Refinanciaciones      NO   \n",
      "1            7     5432449  33015.84      Ezeiza  Efectivo Renovador      NO   \n",
      "2            7     5393285  24707.94      Ezeiza    Refinanciaciones      NO   \n",
      "3            7     5442048  21871.36      Ezeiza  Efectivo Renovador      NO   \n",
      "4            7     5353940   2145.61      Ezeiza    Refinanciaciones      NO   \n",
      "...        ...         ...       ...         ...                 ...     ...   \n",
      "119141      81     5469164   7916.61     Pompeya      Efectivo Nuevo      NO   \n",
      "119142      36     5469150  16792.65  Avellaneda      Efectivo Nuevo      NO   \n",
      "119143      73     5469192  10200.87     Liniers      Efectivo Nuevo      NO   \n",
      "119144      52     5469186  10200.87   San Justo      Efectivo Nuevo      NO   \n",
      "119145      91     5469182  16792.65  San Miguel      Efectivo Nuevo      NO   \n",
      "\n",
      "        CLASE_PLAN  \n",
      "0        RENOVADOR  \n",
      "1            NUEVO  \n",
      "2        RENOVADOR  \n",
      "3            NUEVO  \n",
      "4        RENOVADOR  \n",
      "...            ...  \n",
      "119141   RENOVADOR  \n",
      "119142   RENOVADOR  \n",
      "119143   RENOVADOR  \n",
      "119144   RENOVADOR  \n",
      "119145   RENOVADOR  \n",
      "\n",
      "[119146 rows x 24 columns]\n"
     ]
    }
   ],
   "source": [
    "print(temp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Merging Datasets\n",
      "Finished in 42.51 secs\n"
     ]
    }
   ],
   "source": [
    "print(\"[i] Merging Datasets\")\n",
    "start = time.time()\n",
    "temp1 = clientes.merge(creditos, left_on=\"ID_CLIENTE\", right_on=\"ID_CLIENTE\")\n",
    "temp2 = temp1.merge(pagos, left_on=\"ID_CREDITO\", right_on=\"ID_CREDITO\")\n",
    "everything = temp2.merge(cuotas, left_on=\"ID_CREDITO\", right_on=\"ID_CREDITO\")\n",
    "end = time.time()\n",
    "print(\"Finished in {} secs\".format(round(end-start, 2)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Dropping unnecessary columns\n",
      "Finished in 87.24 secs\n",
      "[i] Normalizing MONTO\n",
      "Finished in 24.33 secs\n",
      "[i] Normalizing INGRESO_NETO\n",
      "Finished in 21.11 secs\n",
      "[i] Normalizing CLASE_PLAN\n",
      "Finished in 24.11 secs\n",
      "[i] Normalizing SEXO\n",
      "Finished in 17.78 secs\n",
      "[i] Normalizing RECIBO\n",
      "Finished in 7.63 secs\n",
      "[i] Normalizing METAL\n",
      "Finished in 22.61 secs\n",
      "[i] Normalizing TIPOLABORAL\n",
      "Finished in 20.18 secs\n",
      "[i] Normalizing SUCURSAL_y\n",
      "Finished in 50.54 secs\n"
     ]
    }
   ],
   "source": [
    "print(\"[i] Dropping unnecessary columns\")\n",
    "drop_columns=None\n",
    "start = time.time()\n",
    "if drop_columns is None:\n",
    "    drop_columns = [\n",
    "        \"TDOC_x\",\n",
    "        \"NROC\",\n",
    "        \"FECHA_ALTA_LABORAL\",\n",
    "        \"SUCURSAL_x\",\n",
    "        \"TDOC_y\",\n",
    "        \"NDOC\",\n",
    "        \"Unnamed: 5\"\n",
    "    ]\n",
    "everything = everything.drop(labels=drop_columns, axis=1)\n",
    "end = time.time()\n",
    "print(\"Finished in {} secs\".format(round(end-start, 2)))\n",
    "\n",
    "\n",
    "print(\"[i] Normalizing MONTO\")\n",
    "start = time.time()\n",
    "normalize_amount(everything, \"MONTO\", 2500)\n",
    "end = time.time()\n",
    "print(\"Finished in {} secs\".format(round(end-start, 2)))\n",
    "\n",
    "\n",
    "print(\"[i] Normalizing INGRESO_NETO\")\n",
    "start = time.time()\n",
    "normalize_amount(everything, \"INGRESO_NETO\", 1000)\n",
    "end = time.time()\n",
    "print(\"Finished in {} secs\".format(round(end-start, 2)))\n",
    "\n",
    "\n",
    "print(\"[i] Normalizing CLASE_PLAN\")\n",
    "start = time.time()\n",
    "normalize_string_mapping(everything, \"CLASE_PLAN\", CLASE_PLAN)\n",
    "end = time.time()\n",
    "print(\"Finished in {} secs\".format(round(end-start, 2)))\n",
    "\n",
    "\n",
    "print(\"[i] Normalizing SEXO\")\n",
    "start = time.time()\n",
    "normalize_string_mapping(everything, \"SEXO\", SEXO)\n",
    "end = time.time()\n",
    "print(\"Finished in {} secs\".format(round(end-start, 2)))\n",
    "\n",
    "\n",
    "print(\"[i] Normalizing RECIBO\")\n",
    "start = time.time()\n",
    "normalize_string_mapping(everything, \"RECIBO\", {'NO':False, 'SI':True})\n",
    "end = time.time()\n",
    "print(\"Finished in {} secs\".format(round(end-start, 2)))\n",
    "\n",
    "\n",
    "print(\"[i] Normalizing METAL\")\n",
    "start = time.time()\n",
    "normalize_string_mapping(everything, \"METAL\", METALES)\n",
    "end = time.time()\n",
    "print(\"Finished in {} secs\".format(round(end-start, 2)))\n",
    "\n",
    "\n",
    "print(\"[i] Normalizing TIPOLABORAL\")\n",
    "start = time.time()\n",
    "normalize_string_mapping(everything, \"TIPOLABORAL\", TIPO_LABORAL)\n",
    "end = time.time()\n",
    "print(\"Finished in {} secs\".format(round(end-start, 2)))\n",
    "\n",
    "\n",
    "print(\"[i] Normalizing SUCURSAL_y\")\n",
    "start = time.time()\n",
    "everything[\"SUCURSAL_y\"] = everything[\"SUCURSAL_y\"].str.strip()\n",
    "normalize_string_mapping(everything, \"SUCURSAL_y\", SUCURSAL_Y)\n",
    "end = time.time()\n",
    "print(\"Finished in {} secs\".format(round(end-start, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Cluster Centers\n",
      "[[3.05283206e+04 6.55319073e+00 1.72932699e+01 1.02567645e+01]\n",
      " [8.41324491e+03 6.17101089e+00 1.77152073e+01 9.56880276e+00]\n",
      " [7.12713607e+04 7.76797953e+00 1.64535319e+01 1.10405739e+01]\n",
      " [4.63427884e+04 7.46618292e+00 1.71650111e+01 1.05194211e+01]\n",
      " [1.79889879e+04 6.27871744e+00 1.77491777e+01 9.78719494e+00]]\n",
      "[1 1 1 ... 1 1 0]\n",
      "[i] Distributions\n",
      "1    310489\n",
      "4    243232\n",
      "0    139404\n",
      "3     51542\n",
      "2     10943\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "\n",
    "\n",
    "#everything = load_merge_all_datasets(\"./data/\")\n",
    "\n",
    "desired_columns = [\"MONTO\", \"TIPOLABORAL\", \"SUCURSAL_y\", \"METAL\"]\n",
    "selected_columns = everything[desired_columns]\n",
    "\n",
    "data_subset = selected_columns.sample(frac=0.05)\n",
    "kmeans = KMeans(n_clusters=5).fit(data_subset)\n",
    "\n",
    "print(\"[i] Cluster Centers\")\n",
    "print(kmeans.cluster_centers_)\n",
    "\n",
    "print(kmeans.labels_)\n",
    "\n",
    "print(\"[i] Distributions\")\n",
    "ps = pd.Series(kmeans.labels_)\n",
    "print(ps.value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
